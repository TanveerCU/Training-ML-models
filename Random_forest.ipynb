{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsUOzXjgrUY7x0TN2UpNZ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TanveerCU/Training-ML-models/blob/main/Random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzThG74EYISO",
        "outputId": "6191a69a-8afd-45a8-d0ae-fd31e720474e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/TanveerCU/Training-Data.git\n",
        "import osn\n",
        "import cv2 as cv\n",
        "!apt install unzip\n",
        "!unzip \"./Training-Data/data.zip\"\n",
        "!unzip \"./Training-Data/alphabet.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Training-Data' already exists and is not an empty directory.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n",
            "Archive:  ./Training-Data/data.zip\n",
            "replace data/dhaka/blur_dhaka_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace data/dhaka/blur_dhaka_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  ./Training-Data/alphabet.zip\n",
            "warning [./Training-Data/alphabet.zip]:  76 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "error [./Training-Data/alphabet.zip]:  reported length of central directory is\n",
            "  -76 bytes too long (Atari STZip zipfile?  J.H.Holm ZIPSPLIT 1.1\n",
            "  zipfile?).  Compensating...\n",
            "replace alphabet/cho/cho1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNhrIK791M84"
      },
      "source": [
        "# **DIGITS ONLY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU3ZjZlNK7Za"
      },
      "source": [
        "train_images=[]\n",
        "train_labels=[]\n",
        "List = os.listdir(\"./data/zero\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/zero/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(0)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/one\")\n",
        "i=1\n",
        "for file in List:\n",
        "  file=\"./data/one/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(1)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/two\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/two/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(2)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/three\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/three/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(3)\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "len(train_images)\n",
        "\n",
        "List = os.listdir(\"./data/four\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/four/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(4)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/five\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/five/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(5)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/six\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/six/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(6)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/seven\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/seven/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(7)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/eight\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/eight/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(8)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/nine\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/nine/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(9)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6cItxAvLG4l"
      },
      "source": [
        "import numpy as np\n",
        "print(len(train_images))\n",
        "train_images=np.array(train_images)\n",
        "train_labels=np.array(train_labels)\n",
        "train_images = train_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO8VoDwbLJUJ"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDBujYl0K7fO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.15, random_state=42)\n",
        "number_of_train = x_train.shape[0]\n",
        "number_of_test = x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ3Qs6sdK7o2"
      },
      "source": [
        "print(number_of_train)\n",
        "print(number_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmAvzjzVK7eN"
      },
      "source": [
        "x_train_flatten = x_train.reshape(number_of_train,x_train.shape[1]*x_train.shape[2])\n",
        "x_test_flatten = x_test .reshape(number_of_test,x_test.shape[1]*x_test.shape[2])\n",
        "print(\"X train flatten\",x_train_flatten.shape)\n",
        "print(\"X test flatten\",x_test_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voaa4IxjK7YF"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "print(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22pLLA7PNJ2A"
      },
      "source": [
        "clf.fit(x_train_flatten, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubmc2ftcK7SD"
      },
      "source": [
        "predictions = clf.predict(x_test_flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQtIJpzbLXLk"
      },
      "source": [
        "score = clf.score(x_test_flatten, y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4EzRQqKLa9j"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWJHNvdaLbOV"
      },
      "source": [
        "cm = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29-deRARLfEW"
      },
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMU3rCun1T6i"
      },
      "source": [
        "# **CHAR ONLY** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpOVtnZQVqR"
      },
      "source": [
        "import os\n",
        "import cv2 as cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6FPrbvf1hTt"
      },
      "source": [
        "train_images=[]\n",
        "train_labels=[]\n",
        "List = os.listdir(\"./alphabet/ko\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/ko/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(10)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/kho\")\n",
        "i=1\n",
        "for file in List:\n",
        "  file=\"./alphabet/kho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(11)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/go\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/go/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(12)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/gho\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/gho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(13)\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "len(train_images)\n",
        "\n",
        "List = os.listdir(\"./alphabet/cho\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/cho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(14)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/jo\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/jo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(15)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/dho\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/dho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(16)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/lo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/lo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(17)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/mo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/mo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(18)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/vo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/vo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(19)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fDI_Aqm1haV"
      },
      "source": [
        "import numpy as np\n",
        "print(len(train_images))\n",
        "train_images=np.array(train_images)\n",
        "train_labels=np.array(train_labels)\n",
        "train_images = train_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuN00zV21hgi"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAbCmBiG1ho9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.15, random_state=42)\n",
        "number_of_train = x_train.shape[0]\n",
        "number_of_test = x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BzlrSCt1hvE"
      },
      "source": [
        "print(number_of_train)\n",
        "print(number_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGI351S21hzs"
      },
      "source": [
        "x_train_flatten = x_train.reshape(number_of_train,x_train.shape[1]*x_train.shape[2])\n",
        "x_test_flatten = x_test .reshape(number_of_test,x_test.shape[1]*x_test.shape[2])\n",
        "print(\"X train flatten\",x_train_flatten.shape)\n",
        "print(\"X test flatten\",x_test_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oluAy8Yj1hn3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "print(clf)\n",
        "\n",
        "clf.fit(x_train_flatten, y_train)\n",
        "\n",
        "\n",
        "predictions = clf.predict(x_test_flatten)\n",
        "\n",
        "\n",
        "\n",
        "score = clf.score(x_test_flatten, y_test)\n",
        "print(score)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "df_cm = pd.DataFrame(cm, index=[\"ko\", \"kho\", \"go\", \"gho\" , \"cho\", \"jo\" , \"dho\", \"lo\", \"mo\", \"vo\"], columns=[\"ko\", \"kho\", \"go\", \"gho\" , \"cho\", \"jo\" , \"dho\", \"lo\", \"mo\", \"vo\"])\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
        "plt.title(all_sample_title, size = 15);\n",
        "                     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOo3FknO2C56"
      },
      "source": [
        "# **BOTH**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdRhxOVF1hfk"
      },
      "source": [
        "train_images=[]\n",
        "train_labels=[]\n",
        "List = os.listdir(\"./data/zero\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/zero/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(0)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/one\")\n",
        "i=1\n",
        "for file in List:\n",
        "  file=\"./data/one/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(1)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/two\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/two/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(2)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/three\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/three/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(3)\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "len(train_images)\n",
        "\n",
        "List = os.listdir(\"./data/four\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/four/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(4)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/five\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./data/five/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(5)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/six\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/six/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(6)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/seven\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/seven/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(7)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/eight\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/eight/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(8)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./data/nine\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./data/nine/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(9)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/ko\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/ko/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(10)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/kho\")\n",
        "i=1\n",
        "for file in List:\n",
        "  file=\"./alphabet/kho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(11)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/go\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/go/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(12)\n",
        "  i+=1\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/gho\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/gho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(13)\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "len(train_images)\n",
        "\n",
        "List = os.listdir(\"./alphabet/cho\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/cho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(14)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/jo\")\n",
        "i=1\n",
        "\n",
        "for file in List:\n",
        "  file=\"./alphabet/jo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(15)\n",
        "\n",
        "  i+=1\n",
        "\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/dho\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/dho/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(16)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/lo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/lo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(17)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/mo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/mo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(18)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)\n",
        "\n",
        "\n",
        "\n",
        "List = os.listdir(\"./alphabet/vo\")\n",
        "i=1\n",
        "#print(len(List))\n",
        "for file in List:\n",
        "  file=\"./alphabet/vo/\"+file\n",
        "  pic=cv.imread(file,0)\n",
        "  train_images.append(pic)\n",
        "  train_labels.append(19)\n",
        "#  print(\"one: \"+(str)(i))\n",
        "  i+=1\n",
        "#print(len(List))\n",
        "#print(len(train_images))\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C47gmm-1hZM"
      },
      "source": [
        "import numpy as np\n",
        "print(len(train_images))\n",
        "train_images=np.array(train_images)\n",
        "train_labels=np.array(train_labels)\n",
        "train_images = train_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okGDpWCx1hSq"
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xastSbkZ1hPW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.15, random_state=42)\n",
        "number_of_train = x_train.shape[0]\n",
        "number_of_test = x_test.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACzngDCV1hMu"
      },
      "source": [
        "print(number_of_train)\n",
        "print(number_of_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pHwqhXB1hGp"
      },
      "source": [
        "x_train_flatten = x_train.reshape(number_of_train,x_train.shape[1]*x_train.shape[2])\n",
        "x_test_flatten = x_test .reshape(number_of_test,x_test.shape[1]*x_test.shape[2])\n",
        "print(\"X train flatten\",x_train_flatten.shape)\n",
        "print(\"X test flatten\",x_test_flatten.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiznQwXw2SDU"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "print(clf)\n",
        "\n",
        "\n",
        "clf.fit(x_train_flatten, y_train)\n",
        "\n",
        "\n",
        "predictions = clf.predict(x_test_flatten)\n",
        "\n",
        "\n",
        "\n",
        "score = clf.score(x_test_flatten, y_test)\n",
        "print(score)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)\n",
        "\n",
        "\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "df_cm = pd.DataFrame(cm, index=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"ko\", \"kho\", \"go\", \"gho\" , \"cho\", \"jo\" , \"dho\", \"lo\", \"mo\", \"vo\"], columns=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"ko\", \"kho\", \"go\", \"gho\" , \"cho\", \"jo\" , \"dho\", \"lo\", \"mo\", \"vo\"])\n",
        "plt.figure(figsize=(19,19))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PccdSyhgcE9"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99fZE2rglSp"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cafofAcQghbI"
      },
      "source": [
        "with open('model_pickle','wb') as file:\n",
        "    pickle.dump(clf,file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVPT6Lsu8ckc"
      },
      "source": [
        "\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "joblib.dump(clf, 'model_joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpl8EhFBgr1j"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HddON-k8npO"
      },
      "source": [
        "mj = joblib.load('model_joblib')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-Ki1dqugtau"
      },
      "source": [
        "with open('model_pickle','rb') as file:\n",
        "    mp = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMhWF7zrj0Cw"
      },
      "source": [
        "prdct = mp.predict(x_test_flatten)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-dqeSmnlfm3"
      },
      "source": [
        "c = metrics.confusion_matrix(y_test, prdct)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3IxOH_jj0Gq"
      },
      "source": [
        "0.9338979240050963"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}